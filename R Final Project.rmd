---
title: "Medical Cost Prediction"
output:
  word_document: default
  html_document: default
date: "2023-11-27"
---

```{r}
#loading libraries
library(regclass)
library(ggplot2)
library(Metrics)


```


```{r}
#reading the CSV file into a data frame named as insurance
insurance <- read.csv("insurance.csv")
head(insurance)
```


```{r}
#checking for null values 
colSums(is.na(insurance))

#checking for duplicated values 
sum(duplicated(insurance))

#removing the duplicated values
insurance <- unique(insurance)

#converting the variables smoker, sex and region to factors
insurance$smoker <- factor(insurance$smoker, levels = c("no", "yes"))
insurance$sex <- factor(insurance$sex, levels = c("male", "female"))
insurance$region <- factor(insurance$region, levels = c("northeast", "northwest", "southeast", "southwest"))
```



```{r}
#association analysis between charges and age
associate(charges ~age,data=insurance, seed= 100, main="Association analysis between Charges and Age")
```
p-value is 0 , the correlation is statistically significant and conclusive. We consider pearson r correlation as there is a linear correlation between charges and age. r = 0.2983082

```{r}
# Fit a linear regression model where 'charges' is the response variable and 'age' is the predictor variable
Model1 <- lm(charges ~ age, data = insurance)

#Summary of the linear regression model
summary(Model1)

# Create a scatter plot of 'charges' against 'age'
plot(charges ~ age, data = insurance, main = "Regression analysis between Charges and Age")

# Add the regression line to the scatter plot
abline(Model1)

# Calculate and display 95% confidence intervals for the coefficients in the linear regression model
confint(Model1, levels = 0.95)
```
r^2 is 8% it is a relatively weak correlation.The intercept of the line is 3190.02 and slope of the line is 257.23. Since the confidence interval of the slope doesn't include 0, the relationship between charges and age is statiscally significant.  The p-value for the coefficient of age is very low (< 2e-16), indicating that there is strong evidence to reject the null hypothesis that the coefficient for age is zero.

The model suggests that there is a significant relationship between the age  and  charges variable. The coefficient for age is positive, indicating that as age increases, charges are expected to increase as well.

```{r}
#association analysis between charges and BMI
associate(charges ~bmi,data=insurance, seed= 100, main= "Association analysis between Charges and BMI")
```
p-value is 0 , the correlation is statistically significant and conclusive. We consider pearson r correlation as there is a linear correlatin between charges and bmi. r = 0.1984008

```{r}
# Fit a linear regression model where 'charges' is the response variable and 'bmi' is the predictor variable
Model2 <- lm(charges ~ bmi, data = insurance)

# Display a summary of the linear regression model
summary(Model2)

# Create a scatter plot of 'charges' against 'bmi'
plot(charges ~ bmi, data = insurance, main = "Regression analysis between Charges and BMI")

# Add the regression line to the scatter plot
abline(Model2)

# Calculate and display 95% confidence intervals for the coefficients in the linear regression model
confint(Model2, levels = 0.95)

```
r^2 is 4% which is a relatively weak correlation.The intercept of the line is 1202.14 and slope of the line is 393.86. Since the confidence interval of the slope doesn't include 0, the relationship between charges and bmi is statiscally significant. The p-value for the coefficient of 'bmi' is very low (2.47e-13), indicating that there is strong evidence to reject the null hypothesis that the coefficient for bmi is zero.

The model suggests that there is a significant relationship between the bmi and charges. The coefficient for bmi is positive, indicating that as bmi increases, charges are expected to increase as well. However, the overall explanatory power of the model is relatively low.


```{r}
#association analysis between charges and sex
associate(charges ~sex,data=insurance, seed= 100, main="Association analysis between Charges and Sex")
```
There is a noticeable difference among bars, so there is an association between charges and sex.  Since the distributions have  extreme outliers, we will compare the medians.Estimated p-value for the medians is 0.962. which is greater than 0.05. We can conclude there is no significant relation between charges and sex. 




```{r}
# Fit a linear regression model where 'charges' is the response variable and 'sex' is the predictor variable
Model3 <- lm(charges ~ sex, data = insurance)

# Display a summary of the linear regression model
summary(Model3)

# Create a scatter plot of 'charges' against 'sex' 
plot(charges ~ sex, data = insurance, main = "Regression analysis between Charges and Sex")

# Add the regression line to the scatter plot
abline(Model3)

# Calculate and display 95% confidence intervals for the coefficients in the linear regression model
confint(Model3, levels = 0.95)



```
r^2 is 0.33% which is very low suggesting that the model doesn't explain much of the variance in the dependent variable.The intercept of the line is 12569.6 and slope of the line is 1405.4. Since the confidence interval of the slope doesn't include 0, the relationship between charges and age is statiscally significant. The p-value for the coefficient of 'sexmale' is 0.0338, which is less than 0.05. This suggests that there is evidence to reject the null hypothesis that the coefficient for 'sexmale' is zero.

The model suggests that there is a significant relationship between the 'sex' variable and the 'charges' variable, but the overall explanatory power of the model is quite low.

```{r}
#association analysis between charges and smoker
associate(charges ~smoker,data=insurance, seed= 100, main="Association analysis between Charges and Smoker")
```
There is a noticeable difference among bars, so there is an association between charges and smokers.  Since the distributions have  extreme outliers, we will compare the medians.Estimated p-value for the medians is 0. which is less than 0.05. We can conclude there is significant relation between charges and if the person is a smoker. 



```{r}
# Fit a linear regression model where 'charges' is the response variable and 'smoker' is the predictor variable
Model4 <- lm(charges ~ smoker, data = insurance)

# Display a summary of the linear regression model
summary(Model4)


# Calculate and display 95% confidence intervals for the coefficients in the linear regression model
confint(Model4, levels = 0.95)

```
r^2 is 6.1%  which is a strong correlation suggesting that the model explains a substantial proportion of the variance in the dependent variable.The intercept of the line is 8440.7 and slope of the line is 23609.6 Since the confidence interval of the slope doesn't include 0, the relationship between charges and age is statiscally significant. The p-value for the coefficient of 'smokeryes' is very low (< 2e-16), indicating that there is strong evidence to reject the null hypothesis that the coefficient for 'smokeryes' is zero.

the model suggests that there is a significant relationship between the smoker variable and the charges variable. The coefficient for smokeryes is positive, indicating that being a smoker is associated with higher charges. 

```{r}
# Create a scatter plot using ggplot2 library with linear regression line
ggplot(insurance, aes(x = smoker, y = charges, group=1)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Scatter Plot of Charges by smoker",
       x = "Smoker", y = "Charges") +
  theme_minimal()

```

```{r}
#association analysis between charges and region
associate(charges ~region,data=insurance, seed= 100, main="Association analysis between Charges and Region")

```
There is a no noticeable difference among bars, so there is no association between charges and region.  Since the distributions have  extreme outliers, we will compare the medians.Estimated p-value for the medians is 0.22, which is greater than 0.05. We can conclude there is no significant relation between charges and region.

```{r}
# Fit a linear regression model where 'charges' is the response variable and 'region' is the predictor variable
Model5 <- lm(charges ~ region, data = insurance)

# Display a summary of the linear regression model
summary(Model5)

# Calculate and display 95% confidence intervals for the coefficients in the linear regression model
confint(Model5, levels = 0.95)



```
r^2 is 0.6%  which is very low suggesting that the model doesn't explain much of the variance in the dependent variable.  The coefficients for the individual regions suggest estimated changes in charges for each region compared to the reference category. However, none of these changes are statistically significant based on the p-values.

The model indicates that there is a statistically significant overall relationship between the categorical variable "region" and the dependent variable "charges." However, when looking at the individual regions, none of them show a statistically significant effect on charges compared to the reference category.

```{r}
# Create a scatter plot using ggplot2 library with linear regression line
ggplot(insurance, aes(x = region, y = charges, group=1)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Scatter Plot of Charges by Region",
       x = "Region", y = "Charges") +
  theme_minimal()
```

```{r}
# Fit a linear regression model using all variables in the 'insurance' dataset
fit1 <- lm(charges ~ ., data = insurance)

summary(fit1)

# Fit a second linear regression model with specific predictor variables
fit2 <- lm(charges ~ age + bmi + children + smoker, data = insurance)

summary(fit2)

# Create a data frame for an individual named Ryan with specific characteristics
Ryan <- data.frame(age = 28,
                   sex = 'male',
                   bmi = 33,
                   children = 3,
                   smoker = "no",
                   region = "southeast")

# Print the predicted health care charges for Ryan using the second linear regression model
print(paste0("Health care charges for Ryan: ", round(predict(fit2, newdata = Ryan), 2)))

# Calculate and print the Root Mean Squared Error (RMSE) for the predictions
predictions1 <- predict(fit2, newdata = insurance)
print(paste0("Root Mean Squared Error (RMSE) for fit2: ", round(rmse(predictions1, insurance$charges), 2)))

```




```{r}
set.seed(1)
# Randomly choose training indices
train_indices <- sample(1:nrow(insurance), 0.8 * nrow(insurance))
train_data <- insurance[train_indices, ]
test_data <- insurance[-train_indices, ]

# Extract the actual charges from the test_data
actual_charges <- test_data$charges

rf_insurance <- randomForest(charges ~ ., data = train_data, importance = TRUE)

# Create a data frame for predictions
predictions <- predict(rf_insurance, newdata = test_data)

# Calculate RMSE
rmse_value <- rmse(predictions, actual_charges)

print(rmse_value)

# View variable importance
importance(rf_insurance)


# Plot variable importance
varImpPlot(rf_insurance)

Ryan <- data.frame(age = 19,
                   sex = 'male',
                   bmi = 27.9,
                   children = 0,
                   smoker = "yes",
                   region = "northwest",
                   charges = 0)

# Update levels of factors in the new data (Ryan)
Ryan$sex <- factor(Ryan$sex, levels = levels(train_data$sex))
Ryan$smoker <- factor(Ryan$smoker, levels = levels(train_data$smoker))
Ryan$region <- factor(Ryan$region, levels = levels(train_data$region))
Ryan$age <- as.integer(Ryan$age)
Ryan$children <- as.integer(Ryan$children)

prediction_for_new_data <- predict(rf_insurance, newdata = Ryan)

print(paste("Predicted charge for Ryan:", round(prediction_for_new_data, 2)))

print(paste0("Health care charges for Ryan: ", round(predict(rf_insurance, newdata = Ryan), 2)))


```




